{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43f83f04",
   "metadata": {},
   "source": [
    "# Skeleton Moment demonstrator\n",
    "\n",
    "*Gareth Howells, January 2022*\n",
    "\n",
    "The notenook provides code samples to explore the effectiveness of moment nased features for handwritten character recognition. The code is deliberately designed to be basic skeleton so as to allow you to experiment with it. For that reason, many parameters are set via global \"constants\" in the cell below and little in the form of parameter or error testing or handling is provided. There are also commented out **print** \"debugging\" commands which you may uncomment to display information if you wish as you explore (or you can use the debugger).\n",
    "\n",
    "The following cell provides imports and constant values used by the system. For simplicity in providing a user interface, variations in performance can be explored by amending the appropraite value of each constants. It is recommended that only the constants under \"values to explore\" are edited."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dca977da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as pltimg\n",
    "import time\n",
    "\n",
    "###############################################\n",
    "## CHANGE THE FOLLOWING PATH BEFORE STARTING ##\n",
    "###############################################\n",
    "# change the following to the location where you have uploaded the test data\n",
    "# there should be two folders within this folder called \"train\" and \"test\"\n",
    "EXAMPLES_LOCATION = \"/home/elr/wgjh1/jupyter/class_1_data/digits/\" \n",
    "\n",
    "# Normally, you should not need to alter the following four values\n",
    "LOCATION_SUFFIX = \".norm\"\n",
    "ROWS = 24 # number of rows in the image (moment value y)\n",
    "COLS = 16 # number of columns in the image (moment value x)\n",
    "\n",
    "# Values to explore===change the following as you proceed with your investigation or amend the driver function to read them in from the keyboard\n",
    "NUMBER_TRAINING_EXAMPLES = 10   # change this to alter the number of training patterns\n",
    "PMAX = 2 # you can increae the p values investigated\n",
    "QMAX = 2 # you can independently change the q values investigated\n",
    "\n",
    "MAX_EXAMPLES = NUMBER_TRAINING_EXAMPLES * 10 # maximum number of traning or testing examples to be read in a given instance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50dd3a4f",
   "metadata": {},
   "source": [
    "## moment calculator\n",
    "\n",
    "The following function calculates the the pq'th moment value $m_{pq}$ for a given image. It is thus the fundamental component of this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe160da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def moment(p,q,image):\n",
    "    dim = image.shape # find dimensions of the image\n",
    "    \n",
    "    sum = 0\n",
    "    \n",
    "    # PUT YOUR CODE HERE\n",
    "    \n",
    "    return sum        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68786fa4",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "## Reading images from the example files\n",
    "\n",
    "set of images from a given file. For simplicity, they are tailored to the file format supplied and hence not generic. They would require modification to read in differing sile fomats although the remainder of the notebook should be applicable with relatively little difficulty.\n",
    "\n",
    "The first function **read_image** reads a single image into position ^^example** in the **images** array. Note that, in the file format supplied, there is an end of line character at the end of each row of the image which is read in and discarded. \n",
    "\n",
    "Note that subsequently images follow immediately after the given image, there is no form of image separator in the file (you can open the file with a simple text editor like **notepad** to see it consists of only *0* and *1* characters\n",
    "\n",
    "The second function **read_images** governs the opening and closing of the files together with reading a set of images from the given file. Note that the location of the files is governed by the constants names and a varaible with the name of the class as a numeral. \"0\", \"1\", \"2\" etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce95f357",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image(f,example,images):\n",
    "\n",
    "    for x in range(ROWS):\n",
    "        for y in range(COLS):\n",
    "            images[example,x,y]=(int(f.read(1))) # read either the 0 or 1 character and convert to an integer 0 or 1\n",
    "        f.read(1) # skip eol character\n",
    "    \n",
    "    return(images)\n",
    "    \n",
    "\n",
    "def read_images(dir_name, examples, class_name,images):\n",
    "\n",
    "    location= EXAMPLES_LOCATION + dir_name + str(class_name) + LOCATION_SUFFIX # construct the filename from the name of the class\n",
    "    \n",
    "    f = open(location)\n",
    "    \n",
    "    for example in range (examples):\n",
    "        read_image(f,example,images)\n",
    "            \n",
    "    return(images)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ef28f3",
   "metadata": {},
   "source": [
    "## Display pattern\n",
    "\n",
    "Another support function to display a range of patterns from an array using **matplotlib**.\n",
    "\n",
    "It displays the first **no** images from the array so requires modification to display a specific image.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8db25dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_patterns(images,no):\n",
    "    \n",
    "    for nxt_img in range(no):\n",
    "        print (nxt_img)\n",
    "        imgplot = plt.imshow(images[nxt_img])\n",
    "        plt.show()\n",
    "        #time.sleep(2) # unblock this and change delay to watch images print one at a time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68cdbce0",
   "metadata": {},
   "source": [
    "## Generate moments for the given image \n",
    "\n",
    "To generate all the required moments for a particular image up to the order governed by **pmax** and **qmax**. \n",
    "\n",
    "The results are stored in a dictionary named **results** where the calculated moment is added to the end of the list of values for all images associated with the named moment $m_{pq}$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4b39311",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_image_moments(pmax,qmax, image, results):\n",
    "\n",
    "    for p in range(pmax):\n",
    "        for q in range(qmax):\n",
    "           \n",
    "            m_name = \"m\" + str(p) + str (q) # generate the \"name\" of the moment to use to index the dictionary of moment values \n",
    "            \n",
    "            m = moment(p,q,image) # calculate the moment value m_pq\n",
    "            \n",
    "            # print(m_name + \" is \"+ str(m) +\"\\n\") # uncomment to see results as they are calculated\n",
    "                                 \n",
    "            results[m_name].append(m) # add the calculated moment to the appropriate entry in the dictionary --- can eliminate variable m if printing the value were not required\n",
    "                        \n",
    "            # print (\"Moments for \" + m_name + \" is \" + str(results[m_name])) # uncomment to see \"running total\" of moment values\n",
    "            \n",
    "    return(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f22bf4",
   "metadata": {},
   "source": [
    "## Generate all Training Feature values\n",
    "\n",
    "This function generates all the required moment values for training by repeatedly calling the **gen_image_moments** function  to generate a dictionary containing all the required training values for a set of patterns. They are stored sequencially via a list associated with each dictionary item. i.e. the value of the moment $m_{pq}$ for the n'th training pattern will be the n'th entry in the list associated by the dictionary entry associted with $m_{pq}$.\n",
    "\n",
    "The class identifier **class_name** of each entry (i.e. the actual class of the training pattern whose values lie at the n'th value of each dictionary entry is added after the moments have been calculated as dictionary entry named **class_id** in the corresponding n'th entry in the list associted with this dictionary item. It will form the target for the Dicision Tree during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3c3eae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_moment_features(class_id,no_training_pats,images,train_features):\n",
    "        \n",
    "    for pattern in range(no_training_pats):\n",
    "        train_features = gen_image_moments(PMAX,QMAX,images[pattern],train_features)\n",
    "        \n",
    "        train_features[\"class_id\"].append(class_id) # add the true class id of the training pattern at the end\n",
    "    \n",
    "    # print(\"Raw Trained Feature values\")\n",
    "    # print(train_features) # uncomment here if you want to see how the \"raw\" dictionary of trained values appears\n",
    "    \n",
    "    return(train_features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4a1f17",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## Read in and calculate the feature values for the test image set ##\n",
    "\n",
    "**test_image** generates the moment feature values for a given image and appends it to the list of feature values returning a list of all the feature values for the image\n",
    "\n",
    "**test_images** drives the process by reading in a number of images given in **no_pats** for a given class given by \n",
    "**class_id**. Note that the file name is contructed using this variable also. The list of feature values is added to the list of lists **test_feature_vals** where each component list consists od the moment features for a given image.\n",
    "\n",
    "NOTE: these function produce a list of lists which each entry in the outer list comprising a list of moment features for a given pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a45e469",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_image(image,pmax,qmax):\n",
    "          \n",
    "    # calculate list of moment values for the image and add it to the initially empty list of values\n",
    "    \n",
    "    test_feature_val = [ moment(p,q,image) for p in range(pmax) for q in range(qmax) ] \n",
    "  \n",
    "    return(test_feature_val)\n",
    "\n",
    "\n",
    "def test_images(class_id,no_pats):\n",
    "    \n",
    "    images = np.zeros((MAX_EXAMPLES,ROWS,COLS)) # empty array to store the test images\n",
    "    \n",
    "    images = read_images(\"test/bs/\",no_pats,class_id,images) # read in the images, this time from the \"test\" folder, this may be modified to use other test files available\n",
    "    \n",
    "    #show_patterns(images,no_pats) # uncomment this statement to see the test images that will be used.\n",
    "    \n",
    "    # Generate the list of lists of test image---each entry is a list of feature values for one pattern\n",
    "    test_feature_vals = [test_image(images[pat],PMAX,QMAX) for pat in range(no_pats)]\n",
    "        \n",
    "    # print(\" Test vals \") # uncomment here to see the test images used for testing\n",
    "    # print(test_feature_vals)\n",
    "    \n",
    "    return(test_feature_vals)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1bdfdbd",
   "metadata": {},
   "source": [
    "Another relatively simple function **generate_feature_dict** which generates an empty Python Dictionary with the names of the moment features paired with a list of the associted values for each pattern together with an additional entry **class_id** whcih contains a list of the id's for each pattern in the order they occur, e.g. the first entry contained the class identifier for the first entry in the correcponding lists of all the feature values. For the following example therefore, the **class_id** would contain a list identifying the class from which each row derives.\n",
    "\n",
    "- 214.0  2759.0  1699.0  21463.0\n",
    "- 167.0  2056.0  1336.0  14440.0\n",
    "- 187.0  2371.0  1554.0  18152.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e4e9bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_feature_dict(feature_names):\n",
    "    \n",
    "    feature_dict = dict()\n",
    "    \n",
    "    for nxt_feature in feature_names:\n",
    "        feature_dict[nxt_feature] = list()\n",
    "        \n",
    "    feature_dict[\"class_id\"] = list()\n",
    "    \n",
    "    return(feature_dict)\n",
    "                                "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e31aad",
   "metadata": {},
   "source": [
    "# Training #\n",
    "\n",
    "This function drives the generation the training for the Decision Tree **test_tree** passed in as a parameter.\n",
    "\n",
    "The images are read into an array called **images**. \n",
    "\n",
    "The feature names are stored in a dictionary with the following format\n",
    "{\"m00\" : list(), \"m01\":list(), \"m10\":list(), \"m11\": list(), \"class_id\" : list()}\n",
    "\n",
    "Training works as follows\n",
    "1. generate a list of the names of the moment features using the p and q numbers tagged onto the end of the character \"m\"\n",
    "2. generate an empty dictinbary to store the generated values\n",
    "3. for each class, read in the required number of training images from the file, generate the moment features, placing the results in the dictionary\n",
    "4. load the training data nto a Pandas DataFrame object\n",
    "5. divide the data frame into the training features and the target class **class_id** \n",
    "6. train the decision tree\n",
    "\n",
    "The above comments are repeated prior to the Python statements associted with them below.\n",
    "\n",
    "It is possible to print out the decision tree generated.This can be quite insightful in gaining an understanding of what is being deduced from the training patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2978d71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classifier(test_tree, no_classes, no_training_examples):\n",
    "    images = np.zeros((MAX_EXAMPLES,ROWS,COLS))\n",
    "    \n",
    "    # generate a list of the names of the moment features using the p and q numbers tagged onto the end of the character \"m\"\n",
    "    feature_names =  [\"m\" + str(p) + str (q) for p in range(PMAX) for q in range(QMAX)] \n",
    "        \n",
    "    # print(feature_names) # uncomment this statement to see the generated names\n",
    "    \n",
    "    # generate an empty dictinbary\n",
    "    panel_cols = generate_feature_dict(feature_names)\n",
    "    \n",
    "    #print(\"cols : \" + str(panel_cols)) # ncomment this statement to see the enoty dixtionary\n",
    "\n",
    "    # for each class, read in the required number of training images from the file, generate the moment features,\n",
    "    # placing the results in the dictionary\n",
    "    \n",
    "    for file_name in range(no_classes):\n",
    "        images= read_images(\"train/br/\",no_training_examples,file_name,images)\n",
    "        \n",
    "        #show_patterns(images,no_training_examples) # uncomment this line to see the training patterns\n",
    "\n",
    "        features = gen_moment_features(file_name,no_training_examples,images,panel_cols)\n",
    "        \n",
    "    #load the training data nto a Pandas DataFrame object:\n",
    "    \n",
    "    df = pd.DataFrame(panel_cols)\n",
    "\n",
    "    #print(df) # uncomment here to see the data frame\n",
    "\n",
    "    # Divide the into the training features and the target class class_id \n",
    "    features = df[feature_names]\n",
    "    \n",
    "    # print( \"FEATURES\")\n",
    "    # print(features) # uncomment here to see the actual dataframe\n",
    "    \n",
    "    target=df['class_id']\n",
    "    test_tree = test_tree.fit(features,target) # train the decision tree\n",
    "   \n",
    "    # tree.plot_tree(test_tree) # uncomment here to see the actual decision tree produced. This can be quite insightful in \n",
    "    # plt.show()                # gaining an understanding of what is being deduced from the training patterns.\n",
    "\n",
    "    return(test_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5141a17e",
   "metadata": {},
   "source": [
    "# A simple function to test your moment calculator #\n",
    "\n",
    "Use the following function initially to test your moment generator.\n",
    "\n",
    "The answer should be:\n",
    "    {'m00': [214.0], 'm01': [2759.0], 'm10': [1699.0], 'm11': [21463.0], 'class_id': []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d3da110c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def moment_tester():\n",
    "    \n",
    "    image = np.zeros((1,ROWS,COLS)) # space for one image\n",
    "    \n",
    "    feature_names = [\"m\" + str(p) + str (q) for p in range(2) for q in range(2)] # generate feature names for moments to order 2 (so we can see the outputs)\n",
    "             \n",
    "    panel_cols = generate_feature_dict(feature_names) # create empty dictionary\n",
    "    \n",
    "    read_images(\"train/br/\", 1, 0,image) # read 1 image from the class 0 training file\n",
    "    \n",
    "    features = gen_image_moments(2,2,image[0],panel_cols) # calculate the moments up to order 2 for this image\n",
    "    \n",
    "    print( \"FEATURES\")\n",
    "    print(features)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dfbe7f8",
   "metadata": {},
   "source": [
    "# Main / Driver Function #\n",
    "\n",
    "Main driver function for the system. Requested how many training classes and repeats the test for a given class and number of examples.\n",
    "\n",
    "Feel free to edit this function to loop and ask for as many training samples as you require or test all classes. Also include error checking. Additionally you could explore changing the order of the moments by reading in the PMAX and QMAX values,\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8d3be324",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2346271/3696114631.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# moment_tester() # use this function first to test your moment calculator. Once complete, comment this line out and uncomment driver\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mdriver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# uncomment here to tun main decision tree classifier.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_2346271/3696114631.py\u001b[0m in \u001b[0;36mdriver\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mno_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"How many training classes?\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mtest_tree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_tree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mno_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNUMBER_TRAINING_EXAMPLES\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# you may wish to reqrite this function to read in the number of training examples from the user\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/jupyterhub/pyvenv/lib/python3.8/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1004\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1005\u001b[0m             )\n\u001b[0;32m-> 1006\u001b[0;31m         return self._input_request(\n\u001b[0m\u001b[1;32m   1007\u001b[0m             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1008\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"shell\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/jupyterhub/pyvenv/lib/python3.8/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1049\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1050\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1051\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "def driver():\n",
    "\n",
    "    test_tree = DecisionTreeClassifier() # untrained decision tree\n",
    "\n",
    "           \n",
    "    no_classes = int(input(\"How many training classes?\"))\n",
    "    test_tree = train_classifier(test_tree, no_classes, NUMBER_TRAINING_EXAMPLES) # you may wish to reqrite this function to read in the number of training examples from the user\n",
    "\n",
    "    # loop classes and class numbers until user manually stops execution\n",
    "    while (True):\n",
    "        class_name = input(\"Test class name>\")\n",
    "        no_examples = int(input(\"how many examples?\"))\n",
    "\n",
    "        test_features = test_images(class_name,no_examples)\n",
    "\n",
    "        #print(\"tree features\") # uncomment here to see the feature values\n",
    "        #print(test_features)\n",
    "\n",
    "        # the results contained as a list of numerals showing the predicted class of each image in turn\n",
    "        print(\"I think the test patterns are: \" + str(test_tree.predict(test_features))) \n",
    "\n",
    "moment_tester() # use this function first to test your moment calculator. Once complete, comment this line out and uncomment driver\n",
    "# driver() # uncomment here to tun main decision tree classifier.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
